[ ] figure out the environment

[ ] state, action, reward, next state
[ ] implement rl algorithm


IMPLEMENT:
[x] action = env.action_space.sample()
[ ] observation, reward, terminated, info = env.step(action)

dones needs to be fixed up

proper resetting 

env.close()

step function

----

i dont like the current organization of files
also want to plug a nn in

need to look at how dones is done - 
    oh i think its if the body hits the ground its weird

are flags set up at all correctly? should they be on the edge of the screen?
add values to the observation

sample action space might be too small, not enough movement

general refactor - make it more readable like tinygrad
